{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPp7F6RdaIluZIUTvplG4s9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlperMehmetOzdemir/CMP719Project/blob/main/CMP719Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UeiGH--Q1l8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision pycocotools matplotlib numpy Pillow psutil\n",
        "!pip install ultralytics  # For YOLOv8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download COCO 2017 Val\n",
        "!mkdir -p data/coco\n",
        "!wget -nc http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P data/coco\n",
        "!wget -nc http://images.cocodataset.org/zips/val2017.zip -P data/coco\n",
        "!unzip -n data/coco/annotations_trainval2017.zip -d data/coco\n",
        "!unzip -n data/coco/val2017.zip -d data/coco/images"
      ],
      "metadata": {
        "id": "TFRTj6lNQ529",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools import mask as maskUtils\n",
        "import time\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil\n",
        "import os"
      ],
      "metadata": {
        "id": "ziVUd-jUxpHF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_IMAGES = 1000\n",
        "CONFIDENCE_THRESHOLD = 0.5"
      ],
      "metadata": {
        "id": "MB4-h5oP1JC0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load Mask R-CNN\n",
        "maskrcnn_model = maskrcnn_resnet50_fpn(pretrained=True).to(device).eval()\n",
        "\n",
        "# Load YOLOv8-seg\n",
        "yolov8_model = YOLO('yolov8x-seg.pt').to(device)"
      ],
      "metadata": {
        "id": "EggTI-IgQ6JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision.transforms import functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "from pycocotools import mask as maskUtils\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "def evaluate_model(model, coco, img_ids, model_type='maskrcnn'):\n",
        "    \"\"\"Evaluate model on COCO dataset\"\"\"\n",
        "    metrics = []\n",
        "\n",
        "    for img_id in img_ids[:NUM_IMAGES]:  # Evaluate on first 50 images\n",
        "        # Load image and annotations\n",
        "        img_info = coco.loadImgs(img_id)[0]\n",
        "        img_path = f\"data/coco/images/val2017/{img_info['file_name']}\"\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        annotations = coco.loadAnns(ann_ids)\n",
        "\n",
        "        # Get ground truth\n",
        "        gt_masks = [coco.annToMask(ann) for ann in annotations]\n",
        "        gt_boxes = [ann['bbox'] for ann in annotations]\n",
        "\n",
        "        # Get image dimensions\n",
        "        img = Image.open(img_path)\n",
        "        img_width, img_height = img.size\n",
        "\n",
        "        # Run inference\n",
        "        start_time = time.time()\n",
        "\n",
        "        if model_type == 'maskrcnn':\n",
        "            # Mask R-CNN inference\n",
        "            image_tensor = F.to_tensor(img).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(image_tensor)[0]\n",
        "\n",
        "            # Process Mask R-CNN outputs\n",
        "            pred_masks = outputs['masks'].cpu().numpy().squeeze(1)\n",
        "            scores = outputs['scores'].cpu().numpy()\n",
        "            keep = scores > CONFIDENCE_THRESHOLD  # Confidence threshold\n",
        "            pred_masks = pred_masks[keep]\n",
        "            pred_boxes = outputs['boxes'].cpu().numpy()[keep]\n",
        "\n",
        "        else:  # YOLOv8\n",
        "            # YOLOv8 inference\n",
        "            try:\n",
        "                results = model(img_path)\n",
        "                result = results[0]  # Get first (and only) result\n",
        "\n",
        "                # Process YOLOv8 outputs\n",
        "                if result.masks is None:  # No detections\n",
        "                    pred_masks = np.zeros((0, img_height, img_width))\n",
        "                    pred_boxes = np.zeros((0, 4))\n",
        "                else:\n",
        "                    pred_masks = result.masks.data.cpu().numpy()\n",
        "                    pred_boxes = result.boxes.xyxy.cpu().numpy()\n",
        "\n",
        "                    # Resize masks to original image dimensions\n",
        "                    resized_masks = []\n",
        "                    for mask in pred_masks:\n",
        "                        mask = cv2.resize(mask.squeeze(), (img_width, img_height))\n",
        "                        resized_masks.append(mask)\n",
        "                    pred_masks = np.array(resized_masks)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image {img_id}: {str(e)}\")\n",
        "                pred_masks = np.zeros((0, img_height, img_width))\n",
        "                pred_boxes = np.zeros((0, 4))\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        # Calculate metrics if we have predictions\n",
        "        if len(pred_boxes) > 0:\n",
        "            # Convert masks to RLE format for pycocotools\n",
        "            pred_rles = [maskUtils.encode(np.asarray(mask > 0.5, order='F'))\n",
        "                        for mask in pred_masks]\n",
        "            gt_rles = [maskUtils.encode(np.asarray(mask, order='F'))\n",
        "                      for mask in gt_masks]\n",
        "\n",
        "            # Calculate IoU\n",
        "            ious = maskUtils.iou(pred_rles, gt_rles, [0]*len(gt_rles))\n",
        "            miou = np.mean(ious) if len(ious) > 0 else 0\n",
        "\n",
        "            # Calculate mAP (simplified version)\n",
        "            tp = np.sum(np.max(ious, axis=1) > 0.5) if len(ious) > 0 else 0\n",
        "            precision = tp / len(pred_boxes)\n",
        "\n",
        "        else:\n",
        "            miou = 0\n",
        "            precision = 0\n",
        "\n",
        "        metric = {\n",
        "            'mAP': precision,\n",
        "            'mIoU': miou,\n",
        "            'Dice': 2 * miou / (1 + miou) if miou > 0 else 0,\n",
        "            'FPS': 1 / (inference_time + 1e-6)  # Avoid division by zero\n",
        "        }\n",
        "\n",
        "        print(\"Metric for:\", img_path)\n",
        "        print(metric)\n",
        "        metrics.append(metric)\n",
        "\n",
        "    # Aggregate metrics\n",
        "    return {\n",
        "        'mAP': np.mean([r['mAP'] for r in metrics]),\n",
        "        'mIoU': np.mean([r['mIoU'] for r in metrics]),\n",
        "        'Dice': np.mean([r['Dice'] for r in metrics]),\n",
        "        'FPS': np.mean([r['FPS'] for r in metrics])\n",
        "    }"
      ],
      "metadata": {
        "id": "SSDv0fRlQ6Lc"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize COCO API\n",
        "coco = COCO('data/coco/annotations/instances_val2017.json')\n",
        "img_ids = coco.getImgIds()[:NUM_IMAGES]\n",
        "\n",
        "# Evaluate models\n",
        "maskrcnn_results = evaluate_model(maskrcnn_model, coco, img_ids, 'maskrcnn')\n",
        "yolov8_results = evaluate_model(yolov8_model, coco, img_ids, 'yolov8')\n",
        "\n",
        "# Display results\n",
        "print(\"Mask R-CNN Results:\", maskrcnn_results)\n",
        "print(\"YOLOv8 Results:\", yolov8_results)"
      ],
      "metadata": {
        "id": "FxIjOFJAQ6N_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Mask R-CNN', 'YOLOv8'],\n",
        "    'mAP@0.5': [maskrcnn_results['mAP'], yolov8_results['mAP']],\n",
        "    'mIoU': [maskrcnn_results['mIoU'], yolov8_results['mIoU']],\n",
        "    'Dice': [maskrcnn_results['Dice'], yolov8_results['Dice']],\n",
        "    'FPS': [maskrcnn_results['FPS'], yolov8_results['FPS']]\n",
        "})\n",
        "\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcJi5sJ4Q6Qk",
        "outputId": "857ec28e-120b-4047-db75-8c3c70a6ee49"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Model   mAP@0.5      mIoU      Dice        FPS\n",
            "0  Mask R-CNN  0.653778  0.194674  0.285754   6.502511\n",
            "1      YOLOv8  0.746885  0.221345  0.313887  13.991079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COCO_CLASS_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana',\n",
        "    'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n",
        "    'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A', 'N/A',\n",
        "    'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book', 'clock',\n",
        "    'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ],
      "metadata": {
        "id": "ezrZaAEgyus-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(img_id, coco):\n",
        "    img_info = coco.loadImgs(img_id)[0]\n",
        "    img_path = f\"data/coco/images/val2017/{img_info['file_name']}\"\n",
        "    image = np.array(Image.open(img_path))\n",
        "    img_height, img_width = image.shape[:2]\n",
        "\n",
        "    # Create figure\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 8))\n",
        "\n",
        "    # Ground truth visualization\n",
        "    ax1.imshow(image)\n",
        "    for ann in coco.loadAnns(coco.getAnnIds(imgIds=img_id)):\n",
        "        # Draw bounding box\n",
        "        bbox = ann['bbox']\n",
        "        x, y, w, h = bbox\n",
        "        rect = plt.Rectangle((x, y), w, h, fill=False,\n",
        "                           color='red', linewidth=2, linestyle='-')\n",
        "        ax1.add_patch(rect)\n",
        "\n",
        "        # Draw segmentation mask\n",
        "        mask = coco.annToMask(ann)\n",
        "        color = np.random.random(3)\n",
        "        image_masked = image.copy()\n",
        "        image_masked[mask == 1] = image_masked[mask == 1] * 0.7 + color * 255 * 0.3\n",
        "        ax1.imshow(image_masked)\n",
        "\n",
        "        # Add label\n",
        "        class_name = COCO_CLASS_NAMES[ann['category_id']]\n",
        "        ax1.text(x, y - 5, class_name,\n",
        "                bbox=dict(facecolor='red', alpha=0.5),\n",
        "                fontsize=8, color='white')\n",
        "    ax1.set_title('Ground Truth')\n",
        "\n",
        "    # Mask R-CNN visualization\n",
        "    ax2.imshow(image)\n",
        "    image_tensor = F.to_tensor(Image.open(img_path)).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = maskrcnn_model(image_tensor)[0]\n",
        "\n",
        "    for i in range(len(outputs['boxes'])):\n",
        "        if outputs['scores'][i] < CONFIDENCE_THRESHOLD:  # Confidence threshold\n",
        "            continue\n",
        "\n",
        "        # Draw bounding box\n",
        "        box = outputs['boxes'][i].cpu().numpy()\n",
        "        x1, y1, x2, y2 = box\n",
        "        width = x2 - x1\n",
        "        height = y2 - y1\n",
        "        rect = plt.Rectangle((x1, y1), width, height,\n",
        "                           fill=False, color='blue', linewidth=2)\n",
        "        ax2.add_patch(rect)\n",
        "\n",
        "        # Draw segmentation mask\n",
        "        mask = outputs['masks'][i].squeeze().cpu().numpy() > CONFIDENCE_THRESHOLD\n",
        "        color = np.random.random(3)\n",
        "        image_masked = image.copy()\n",
        "        image_masked[mask] = image_masked[mask] * 0.7 + color * 255 * 0.3\n",
        "        ax2.imshow(image_masked)\n",
        "\n",
        "        # Add label and confidence\n",
        "        class_name = COCO_CLASS_NAMES[outputs['labels'][i].item()]\n",
        "        score = outputs['scores'][i].item()\n",
        "        ax2.text(x1, y1 - 5, f\"{class_name}: {score:.2f}\",\n",
        "                bbox=dict(facecolor='blue', alpha=0.5),\n",
        "                fontsize=8, color='white')\n",
        "    ax2.set_title('Mask R-CNN')\n",
        "\n",
        "    # YOLOv8 visualization\n",
        "    ax3.imshow(image)\n",
        "    results = yolov8_model(img_path)\n",
        "    result = results[0]\n",
        "\n",
        "    if result.masks is not None:\n",
        "        for i in range(len(result.boxes)):\n",
        "            if result.boxes.conf[i] < CONFIDENCE_THRESHOLD:  # Confidence threshold\n",
        "                continue\n",
        "\n",
        "            # Draw bounding box\n",
        "            box = result.boxes.xyxy[i].cpu().numpy()\n",
        "            x1, y1, x2, y2 = box\n",
        "            width = x2 - x1\n",
        "            height = y2 - y1\n",
        "            rect = plt.Rectangle((x1, y1), width, height,\n",
        "                               fill=False, color='green', linewidth=2)\n",
        "            ax3.add_patch(rect)\n",
        "\n",
        "            # Draw segmentation mask\n",
        "            mask = result.masks.data[i].cpu().numpy()\n",
        "            mask = cv2.resize(mask.squeeze(), (img_width, img_height)) > CONFIDENCE_THRESHOLD\n",
        "            color = np.random.random(3)\n",
        "            image_masked = image.copy()\n",
        "            image_masked[mask] = image_masked[mask] * 0.7 + color * 255 * 0.3\n",
        "            ax3.imshow(image_masked)\n",
        "\n",
        "            # Add label and confidence\n",
        "            class_id = int(result.boxes.cls[i].item())\n",
        "            class_name = yolov8_model.names[class_id]\n",
        "            score = result.boxes.conf[i].item()\n",
        "            ax3.text(x1, y1 - 5, f\"{class_name}: {score:.2f}\",\n",
        "                    bbox=dict(facecolor='green', alpha=0.5),\n",
        "                    fontsize=8, color='white')\n",
        "    ax3.set_title('YOLOv8')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "awG9wO2UlVAp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_id in img_ids[:3]:\n",
        "    visualize_results(img_id, coco)"
      ],
      "metadata": {
        "id": "XYh4JqPlycoN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}